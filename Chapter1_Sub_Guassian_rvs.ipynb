{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Problem 1.1** Let $X_1, \\dots, X_n$ be independent random variables such that $\\mathbb{E}(X_i) = 0$ and $X_i \\sim \\text{subE}(\\lambda)$. For any vector $a = (a_1, \\dots, a_n)^\\top \\in \\mathbb{R}^n$, define the weighted sum\n",
    "$$\n",
    "S(a) = \\sum_{i=1}^n a_i X_i.\n",
    "$$\n",
    "Show that for any $t > 0$ we have\n",
    "$$\n",
    "\\mathbb{P}(|S(a)| > t) \\le 2 \\exp \\left[ -C \\left( \\frac{t^2}{\\lambda^2 |a|_2^2} \\wedge \\frac{t}{\\lambda |a|_\\infty} \\right) \\right],\n",
    "$$\n",
    "for some positive constant $C$.\n"
   ],
   "id": "ee529b95f90c256"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "***\n",
    "**Proof 1.1**\n",
    "### Step 1: MGF of Each Scaled Term\n",
    "By the definition of a sub-exponential random variable $X_i$:\n",
    "$$\\mathbb{E}[e^{sX_i}] \\le \\exp\\left(\\frac{s^2\\lambda^2}{2}\\right) \\quad \\text{for all } |s| \\le \\frac{1}{\\lambda}$$\n",
    "For each scaled term $a_i X_i$:\n",
    "$$\\mathbb{E}[e^{s(a_iX_i)}] \\le \\exp\\left(\\frac{s^2 a_i^2 \\lambda^2}{2}\\right), \\quad \\text{whenever } |s| \\le \\frac{1}{\\lambda|a_i|}$$\n",
    "\n",
    "### Step 2: MGF for the Weighted Sum\n",
    "By independence, the MGF of the sum $S(a) = \\sum a_i X_i$ is the product of the individual MGFs:\n",
    "$$\\mathbb{E}[e^{sS(a)}] = \\prod_{i=1}^n \\mathbb{E}[e^{sa_i X_i}] \\le \\exp\\left(\\frac{s^2 \\lambda^2 \\|a\\|_2^2}{2}\\right)$$\n",
    "This bound is valid for $|s| \\le \\frac{1}{\\lambda \\|a\\|_\\infty}$. For simplicity, let $v^2 := \\lambda^2 \\|a\\|_2^2$ and $b := \\lambda \\|a\\|_\\infty$. The bound becomes:\n",
    "$$\\mathbb{E}[e^{sS(a)}] \\le \\exp\\left(\\frac{s^2 v^2}{2}\\right) \\quad \\text{for } |s| \\le \\frac{1}{b}$$\n",
    "\n",
    "### Step 3: Apply the Chernoff Bound\n",
    "Applying Markov's inequality for any $s \\in (0, 1/b]$ gives the Chernoff bound:\n",
    "$$\\mathbb{P}(S(a) \\ge t) \\le e^{-st}\\mathbb{E}[e^{sS(a)}] \\le \\exp\\left(-st + \\frac{s^2 v^2}{2}\\right)$$\n",
    "Minimizing this bound by choosing the best $s$ yields two regimes:\n",
    "* **Quadratic regime** ($t \\le v^2/b$): Choose $s^* = t/v^2$.\n",
    "    $$\\mathbb{P}(S(a) \\ge t) \\le \\exp\\left(-\\frac{t^2}{2v^2}\\right)$$\n",
    "* **Linear regime** ($t > v^2/b$): Choose $s^* = 1/b$.\n",
    "    $$\\mathbb{P}(S(a) \\ge t) \\le \\exp\\left(-\\frac{t}{2b}\\right)$$\n",
    "Combining these cases gives a single expression for the tail bound:\n",
    "$$\\mathbb{P}(S(a) \\ge t) \\le \\exp\\left[-\\frac{1}{2}\\left(\\frac{t^2}{v^2} \\wedge \\frac{t}{b}\\right)\\right]$$\n",
    "\n",
    "### Step 4: Combine Tails for the Final Result\n",
    "Using the union bound to control both tails ($\\mathbb{P}(|S(a)| > t) \\le \\mathbb{P}(S(a) > t) + \\mathbb{P}(-S(a) > t)$) gives:\n",
    "$$\\mathbb{P}(|S(a)| > t) \\le 2 \\exp\\left[-\\frac{1}{2}\\left(\\frac{t^2}{v^2} \\wedge \\frac{t}{b}\\right)\\right]$$\n",
    "Finally, substituting back the definitions for $v^2$ and $b$ gives the result with $C=1/2$:\n",
    "$$\\mathbb{P}(|S(a)| > t) \\le 2 \\exp\\left[-\\frac{1}{2}\\left(\\frac{t^2}{\\lambda^2 \\|a\\|_2^2} \\wedge \\frac{t}{\\lambda \\|a\\|_\\infty}\\right)\\right] \\quad \\square$$\n",
    "\n",
    "***\n",
    "The proof uses an optimized Chernoff bound on the MGF of the weighted sum $S(a) = \\sum a_i X_i$ to derive a concentration inequality with two distinct regimes determined by the $\\|a\\|_2$ and $\\|a\\|_\\infty$ norms, which simplifies to Bernstein's inequality(Theorem 1.13) for the special case where all weights $a_i = 1/n$.\\\n",
    "**Theorem 1.13 (Bernstein's inequality)**.Let $X_1, \\dots, X_n$ be independent random variables such that $\\mathbb{E}(X_i) = 0$ and $X_i \\sim \\text{subE}(\\lambda)$. Define\n",
    "$$\n",
    "\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i,\n",
    "$$\n",
    "Then for any $t > 0$ we have\n",
    "$$\n",
    "\\mathbb{P}(\\bar{X} > t) \\lor \\mathbb{P}(\\bar{X} < -t) \\le \\exp\\left[-\\frac{n}{2}\\left(\\frac{t^2}{\\lambda^2} \\wedge \\frac{t}{\\lambda}\\right)\\right].\n",
    "$$"
   ],
   "id": "4249df43f473028b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "***\n",
    "**Problem 1.2**\n",
    "A random variable $X$ has $\\chi^2_n$ (chi–squared with $n$ degrees of freedom) if it has the same distribution as $Z_1^2+\\cdots+Z_n^2$, where $Z_1,\\ldots,Z_n$ are i.i.d. $\\mathcal{N}(0,1)$.\n",
    "\n",
    "**(a)** Let $Z \\sim \\mathcal{N}(0,1)$. Show that the moment generating function of $Y = Z^2 - 1$ satisfies\n",
    "$$\n",
    "\\phi(s) := \\mathbb{E}[e^{sY}] =\n",
    "\\begin{cases}\n",
    "\\dfrac{e^{-s}}{\\sqrt{1-2s}}, & \\text{if } s<\\tfrac{1}{2},\\\\[6pt]\n",
    "\\infty, & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**(b)** Show that for all $0 < s < \\tfrac{1}{2}$,\n",
    "$$\n",
    "\\phi(s) \\le \\exp\\!\\left(\\frac{s^2}{1-2s}\\right).\n",
    "$$\n",
    "\n",
    "**(c)** Conclude that\n",
    "$$\n",
    "\\mathbb{P}\\!\\left(Y > 2t + 2\\sqrt{t}\\right) \\le e^{-t}.\n",
    "$$\n",
    "*Hint:* Use the convexity inequality $\\sqrt{1+u} \\le 1 + \\tfrac{u}{2}$.\n",
    "\n",
    "**(d)** Show that if $X \\sim \\chi^2_n$, then, with probability at least $1-\\delta$, it holds\n",
    "$$\n",
    "X \\le n + 2\\sqrt{n\\log(1/\\delta)} + 2\\log\\!\\big(1/\\delta\\big).\n",
    "$$\n"
   ],
   "id": "1c5b21b6e2f56f9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "***\n",
    "\n",
    "**Proof 1.2**\n",
    "\n",
    "### (a) Exact MGF of $Y = Z^2 - 1$\n",
    "\n",
    "For $Z \\sim \\mathcal{N}(0,1)$, the MGF of $Z^2$ is $\\mathbb{E}[e^{s Z^2}] = (1-2s)^{-1/2}$ for $s < \\tfrac{1}{2}$. Hence, for $Y = Z^2 - 1$,\n",
    "$$\n",
    "\\phi(s) := \\mathbb{E}[e^{sY}] = e^{-s}\\,\\mathbb{E}[e^{s Z^2}]\n",
    "= \\frac{e^{-s}}{\\sqrt{1-2s}}, \\quad s<\\tfrac{1}{2},\n",
    "$$\n",
    "and $\\phi(s)=\\infty$ for $s \\ge \\tfrac{1}{2}$.\n",
    "\n",
    "### (b) Upper bound on $\\phi(s)$\n",
    "\n",
    "Using the inequality $-\\log(1-u) \\le u + \\tfrac{u^2}{2(1-u)}$ for $u \\in [0,1)$, with $u=2s \\in (0,1)$,\n",
    "$$\n",
    "-\\tfrac{1}{2}\\log(1-2s) \\le s + \\frac{s^2}{1-2s}.\n",
    "$$\n",
    "Therefore,\n",
    "$$\n",
    "\\log \\phi(s) = -s - \\tfrac{1}{2}\\log(1-2s)\n",
    "\\le -s + \\left(s + \\frac{s^2}{1-2s}\\right)\n",
    "= \\frac{s^2}{1-2s},\n",
    "$$\n",
    "so for all $0<s<\\tfrac{1}{2}$,\n",
    "$$\n",
    "\\phi(s) \\le \\exp\\!\\left(\\frac{s^2}{1-2s}\\right).\n",
    "$$\n",
    "\n",
    "### (c) One–sided tail for $Y$\n",
    "\n",
    "By Chernoff,\n",
    "$$\n",
    "\\mathbb{P}(Y \\ge x) \\le \\inf_{0<s<1/2} \\exp\\!\\left(-s x\\right)\\phi(s)\n",
    "\\le \\inf_{0<s<1/2} \\exp\\!\\left(-s x + \\frac{s^2}{1-2s}\\right).\n",
    "$$\n",
    "Choose\n",
    "$$\n",
    "s^\\star = \\frac{\\sqrt{t}}{1+2\\sqrt{t}} \\in (0,\\tfrac{1}{2}), \\qquad x = 2t + 2\\sqrt{t}.\n",
    "$$\n",
    "Then $1-2s^\\star = \\tfrac{1}{1+2\\sqrt{t}}$, and a direct calculation gives\n",
    "$$\n",
    "- s^\\star x + \\frac{(s^\\star)^2}{1-2s^\\star} = -t.\n",
    "$$\n",
    "Hence,\n",
    "$$\n",
    "\\mathbb{P}\\!\\left(Y > 2t + 2\\sqrt{t}\\right) \\le e^{-t}.\n",
    "$$\n",
    "\n",
    "### (d) Upper tail for $\\chi^2_n$\n",
    "\n",
    "Let $X \\sim \\chi^2_n$. Write $X = \\sum_{i=1}^n Z_i^2$ with $Z_i \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1)$, and set $Y_i := Z_i^2 - 1$. Then $X - n = \\sum_{i=1}^n Y_i$. By independence and part (b),\n",
    "$$\n",
    "\\mathbb{E}\\!\\left[e^{s\\sum_{i=1}^n Y_i}\\right] = \\phi(s)^n \\le \\exp\\!\\left(\\frac{n s^2}{1-2s}\\right), \\quad 0<s<\\tfrac{1}{2}.\n",
    "$$\n",
    "Chernoff then gives, for any $x>0$,\n",
    "$$\n",
    "\\mathbb{P}\\!\\left(\\sum_{i=1}^n Y_i \\ge x\\right)\n",
    "\\le \\inf_{0<s<1/2} \\exp\\!\\left(-s x + \\frac{n s^2}{1-2s}\\right).\n",
    "$$\n",
    "Pick\n",
    "$$\n",
    "s^\\star = \\frac{\\sqrt{t}}{1+2\\sqrt{t}}, \\qquad x = 2\\sqrt{n\\,t} + 2t,\n",
    "$$\n",
    "which yields\n",
    "$$\n",
    "- s^\\star x + \\frac{n (s^\\star)^2}{1-2s^\\star} = -t.\n",
    "$$\n",
    "Thus, for any $t>0$,\n",
    "$$\n",
    "\\mathbb{P}\\!\\left(X - n \\ge 2\\sqrt{n\\,t} + 2t\\right) \\le e^{-t}.\n",
    "$$\n",
    "Setting $t = \\log(1/\\delta)$ gives, with probability at least $1-\\delta$,\n",
    "$$\n",
    "X \\le n + 2\\sqrt{n\\log(1/\\delta)} + 2\\log\\!\\big(1/\\delta\\big).\n",
    "$$\n",
    "\n",
    "***\n",
    " Each centered square $Y=Z^2-1$ is **sub-exponential** with parameters $(\\nu^2,b)=(4,4)$.\n",
    "- Therefore $X-n=\\sum_{i=1}^n Y_i$ is sub-exponential with $(4n,4)$ and satisfies a **Bernstein (quadratic/linear) two-regime** tail:\n",
    "  $$\n",
    "  \\mathbb{P}(X-n\\ge u) \\le \\exp\\!\\left[-\\tfrac12\\left(\\frac{u^2}{4n}\\wedge \\frac{u}{4}\\right)\\right].\n",
    "  $$\n",
    "- Choosing $u=2\\sqrt{nt}+2t$ yields the standard **$\\chi^2$ upper tail** $\\mathbb{P}(X-n\\ge 2\\sqrt{nt}+2t)\\le e^{-t}$ (up to constants via the generic sub-exponential bound, exactly via the optimized Chernoff step)."
   ],
   "id": "188d03e06c118fa4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "***\n",
    "\n",
    "**Problem 1.3.** Let $X_1, X_2, \\ldots$ be an infinite sequence of sub-Gaussian random variables with variance proxy $\\sigma_i^2 = C(\\log i)^{-1}$. Show that for $C$ large enough, we get\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\!\\left[\\max_{i \\ge 2} X_i\\right] < \\infty .\n",
    "$$\n",
    "\n"
   ],
   "id": "6e1a08c2ea1fde9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "***\n",
    "\n",
    "**Proof 1.3**\n",
    "\n",
    "### Step 1 : Tail of each $X_i$.\n",
    "Sub-Gaussianity with proxy $\\sigma_i^2$ gives, for all $t>0$,\n",
    "$$\n",
    "\\mathbb{P}(X_i>t) \\;\\le\\; \\exp\\!\\left(-\\frac{t^2}{2\\sigma_i^2}\\right)\n",
    "\\;=\\; \\exp\\!\\left(-\\frac{t^2\\log i}{2C}\\right)\n",
    "\\;=\\; i^{-\\alpha(t)},\n",
    "\\quad\\text{where }\\ \\alpha(t):=\\frac{t^2}{2C}.\n",
    "$$\n",
    "\n",
    "### Step 2 : Tail of the supremum via a union bound.\n",
    "Let $M:=\\sup_{i\\ge 2} X_i$. Then, for any $t>0$,\n",
    "$$\n",
    "\\mathbb{P}(M>t)\n",
    "\\;=\\;\\mathbb{P}\\!\\left(\\exists i\\ge 2: X_i>t\\right)\n",
    "\\;\\le\\;\\sum_{i\\ge 2}\\mathbb{P}(X_i>t)\n",
    "\\;\\le\\;\\sum_{i\\ge 2} i^{-\\alpha(t)}.\n",
    "$$\n",
    "When $\\alpha(t)>1$ (i.e., $t>\\sqrt{2C}$), the series is summable and admits the bound\n",
    "$$\n",
    "\\sum_{i\\ge 2} i^{-\\alpha(t)}\n",
    "\\;\\le\\; 1+\\int_{1}^{\\infty} x^{-\\alpha(t)}\\,dx\n",
    "\\;=\\; 1+\\frac{1}{\\alpha(t)-1}\n",
    "\\;=\\; 1+\\frac{1}{t^2/(2C)-1}\n",
    "\\;\\le\\; \\frac{K_C}{t^2}\n",
    "$$\n",
    "for all $t\\ge T:=2\\sqrt{2C}$ and some constant $K_C>0$ depending only on $C$ (the last inequality is a simple algebraic bound).\n",
    "\n",
    "Thus,\n",
    "$$\n",
    "\\mathbb{P}(M>t) \\;\\le\\;\n",
    "\\begin{cases}\n",
    "1, & 0<t<T,\\\\[4pt]\n",
    "\\displaystyle \\frac{K_C}{t^2}, & t\\ge T.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### Step 3 : Integrate the tail to get the expectation.\n",
    "Using the layer-cake representation,\n",
    "$$\n",
    "\\mathbb{E}[M]\n",
    "\\;=\\; \\int_{0}^{\\infty} \\mathbb{P}(M>t)\\,dt\n",
    "\\;\\le\\; \\underbrace{\\int_{0}^{T} 1\\,dt}_{=\\,T}\n",
    "\\;+\\; \\underbrace{\\int_{T}^{\\infty} \\frac{K_C}{t^2}\\,dt}_{=\\,K_C/T}\n",
    "\\;<\\;\\infty .\n",
    "$$\n",
    "Choosing $T=2\\sqrt{2C}$ gives a finite numerical bound:\n",
    "$$\n",
    "\\mathbb{E}[M] \\;\\le\\; 2\\sqrt{2C} \\;+\\; \\frac{K_C}{2\\sqrt{2C}} \\;<\\;\\infty .\n",
    "$$\n",
    "\n",
    "Therefore, for any fixed $C>0$ (in particular, for $C$ “large enough”), we have\n",
    "$$\n",
    "\\mathbb{E}\\!\\left[\\max_{i\\ge 2} X_i\\right] < \\infty .\n",
    "$$\n",
    "\n",
    "***\n",
    "\n",
    "Even with infinitely many variables, the spreads shrink as $\\sigma_i^2=C/\\log i$, so the chance that **any** $X_i$ exceeds a high level $t$ behaves like a summable series $\\sum i^{-t^2/(2C)}$. Past the “critical height” $t\\approx\\sqrt{2C}$, this tail decays fast enough (roughly like $t^{-2}$) that the layer-cake integral $\\int_0^\\infty \\mathbb P(\\sup_i X_i>t)\\,dt$ is finite, hence $\\mathbb E[\\sup_{i\\ge2} X_i]<\\infty$.\n",
    "\n",
    "Interpretation: the explosion from “infinitely many chances” is overpowered by “each chance is weaker.” This is a sharp balance in high-dimensional settings: if complexity-indexed candidates are increasingly regularized (smaller variance proxies), the overall maximum remains controlled in expectation—even without assuming independence.\n",
    "\n",
    "***"
   ],
   "id": "3058131a4706303d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
